# Open5e Developer RAG Server

RAG-powered chatbot for Open5e API and Frontend source code. Ask questions about the Django REST API backend and Nuxt.js frontend.

## Quick Start

```bash
npm install
npm run build
npm start
```

## Index Stats

| Metric | Count |
|--------|-------|
| Sources | 214 |
| Chunks | 484 |
| Vectors | 484 |
| Embedding Model | openai/text-embedding-3-large |

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `PORT` | No | HTTP server port (default: 8080) |
| `OPENAI_API_KEY` | For /chat | OpenAI API key for chat endpoint |
| `OPENAI_MODEL` | No | Model for chat (default: gpt-5-nano-2025-08-07) |

## Deploy to Railway

1. Push to GitHub
2. Connect repo to Railway
3. Add `OPENAI_API_KEY` environment variable (for /chat)
4. Deploy

## HTTP Endpoints

### Health Check
```bash
curl https://your-app.railway.app/health
```

### Search
```bash
curl -X POST https://your-app.railway.app/search \
  -H "Content-Type: application/json" \
  -d '{"query": "your search query", "mode": "keyword", "top_k": 10}'
```

### Chat (RAG + LLM)
```bash
curl -X POST https://your-app.railway.app/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What is...?"}'
```

### List Sources
```bash
curl https://your-app.railway.app/sources
```

## MCP Integration

Add to your MCP client config:
```json
{
  "mcpServers": {
    "open5e-rag": {
      "command": "node",
      "args": ["path/to/dist/index.js"]
    }
  }
}
```

---
*Generated by IndexFoundry*
